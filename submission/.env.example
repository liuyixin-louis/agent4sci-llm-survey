# Environment Variables for LLM Surveying LLMs System
# Copy this file to .env and fill in your actual API keys

# REQUIRED: At least one LLM API key
# Claude API (Recommended for primary system)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OPTIONAL: Additional LLM providers
# OpenAI GPT models
OPENAI_API_KEY=your_openai_api_key_here

# Google Gemini models
GOOGLE_API_KEY=your_google_api_key_here

# Mistral models
MISTRAL_API_KEY=your_mistral_api_key_here

# xAI Grok models
XAI_API_KEY=your_xai_api_key_here

# OPTIONAL: Research features (Highly recommended)
# Perplexity for real-time research
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# OPTIONAL: Alternative providers
OPENROUTER_API_KEY=your_openrouter_api_key_here
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
OLLAMA_API_KEY=your_ollama_api_key_here

# Data paths (Optional - system will use default if not set)
# Path to SciMCP database (if you have it locally)
SCIMCP_DATA_PATH=/path/to/scimcp/data

# Cache directory for storing LLM responses
CACHE_DIR=./cache

# API Configuration
# FastAPI settings
API_HOST=0.0.0.0
API_PORT=8000

# Development settings
DEBUG=false
LOG_LEVEL=INFO

# Rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=60

# Model preferences (optional - will use defaults if not set)
MAIN_MODEL=claude-3-5-sonnet-20241022
RESEARCH_MODEL=perplexity-llama-3.1-sonar-large-128k-online
FALLBACK_MODEL=gpt-4o-mini