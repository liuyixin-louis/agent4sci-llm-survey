{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Data Loading Example - LLM Survey Generator\n",
    "\n",
    "This notebook demonstrates how to load research papers from various sources for survey generation.\n",
    "\n",
    "## Supported Data Sources\n",
    "1. **Parquet Files** - Pre-indexed paper datasets\n",
    "2. **ArXiv API** - Direct paper retrieval by ID or search\n",
    "3. **Semantic Scholar** - Academic paper database\n",
    "4. **JSON/CSV Files** - Custom paper collections\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path('.').absolute().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f'‚úÖ Project root: {project_root}')\n",
    "print(f'‚úÖ Python version: {sys.version.split()[0]}')\n",
    "\n",
    "# Import project modules\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.search_engine import SearchEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Loading from Parquet Files\n",
    "\n",
    "Parquet files provide the fastest way to load large paper datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Check if data path is configured\n",
    "data_path = os.environ.get('SCIMCP_DATA_PATH')\n",
    "if data_path:\n",
    "    print(f'üìÇ Data path: {data_path}')\n",
    "    \n",
    "    # Load papers from parquet\n",
    "    print('‚è≥ Loading papers from parquet file...')\n",
    "    papers_df = loader.load_from_parquet(data_path)\n",
    "    \n",
    "    print(f'‚úÖ Loaded {len(papers_df):,} papers')\n",
    "    print(f'\\nüìä Dataset Overview:')\n",
    "    print(f'  ‚Ä¢ Date range: {papers_df[\"updated\"].min()} to {papers_df[\"updated\"].max()}')\n",
    "    print(f'  ‚Ä¢ Columns: {list(papers_df.columns)}')\n",
    "    \n",
    "    # Display sample\n",
    "    print('\\nüìÑ Sample papers:')\n",
    "    display(papers_df.head(3)[['title', 'authors', 'updated']])\n",
    "else:\n",
    "    print('‚ö†Ô∏è SCIMCP_DATA_PATH not set. Using sample data.')\n",
    "    \n",
    "    # Create sample data\n",
    "    papers_df = pd.DataFrame([\n",
    "        {\n",
    "            'title': 'Attention Is All You Need',\n",
    "            'abstract': 'The dominant sequence transduction models...',\n",
    "            'authors': ['Vaswani et al.'],\n",
    "            'updated': '2017-06-12'\n",
    "        },\n",
    "        {\n",
    "            'title': 'BERT: Pre-training of Deep Bidirectional Transformers',\n",
    "            'abstract': 'We introduce BERT, a new language representation model...',\n",
    "            'authors': ['Devlin et al.'],\n",
    "            'updated': '2018-10-11'\n",
    "        }\n",
    "    ])\n",
    "    print(f'‚úÖ Created {len(papers_df)} sample papers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Topic-Based Filtering\n",
    "\n",
    "Filter papers by topic using keyword search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter papers by topic\n",
    "topic = \"Large Language Models\"\n",
    "\n",
    "print(f'üîç Filtering papers on topic: \"{topic}\"')\n",
    "\n",
    "# Method 1: Simple keyword filtering\n",
    "keywords = ['language model', 'transformer', 'gpt', 'bert', 'llm']\n",
    "pattern = '|'.join(keywords)\n",
    "\n",
    "filtered_df = papers_df[\n",
    "    papers_df['title'].str.lower().str.contains(pattern, na=False) |\n",
    "    papers_df['abstract'].str.lower().str.contains(pattern, na=False)\n",
    "]\n",
    "\n",
    "print(f'‚úÖ Found {len(filtered_df):,} papers matching keywords')\n",
    "\n",
    "# Display distribution by year\n",
    "if 'updated' in filtered_df.columns and len(filtered_df) > 0:\n",
    "    filtered_df['year'] = pd.to_datetime(filtered_df['updated']).dt.year\n",
    "    year_counts = filtered_df['year'].value_counts().sort_index()\n",
    "    \n",
    "    print('\\nüìà Papers by year:')\n",
    "    for year, count in year_counts.tail(5).items():\n",
    "        bar = '‚ñà' * int(count / year_counts.max() * 20)\n",
    "        print(f'  {year}: {bar} {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Using BM25 Search Engine\n",
    "\n",
    "BM25 provides more sophisticated relevance-based search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize search engine\n",
    "print('üîß Initializing BM25 search engine...')\n",
    "search_engine = SearchEngine()\n",
    "\n",
    "# Build index from papers\n",
    "if len(papers_df) > 0:\n",
    "    papers_list = papers_df.to_dict('records')\n",
    "    search_engine.build_index(papers_list)\n",
    "    print(f'‚úÖ Indexed {len(papers_list):,} papers')\n",
    "    \n",
    "    # Perform searches\n",
    "    queries = [\n",
    "        \"transformer attention mechanism\",\n",
    "        \"few-shot learning prompting\",\n",
    "        \"reinforcement learning from human feedback\"\n",
    "    ]\n",
    "    \n",
    "    print('\\nüîç Search Results:')\n",
    "    for query in queries:\n",
    "        results = search_engine.search(query, top_k=3)\n",
    "        print(f'\\nQuery: \"{query}\"')\n",
    "        for i, paper in enumerate(results, 1):\n",
    "            print(f'  {i}. {paper.get(\"title\", \"Untitled\")[:60]}...')\n",
    "else:\n",
    "    print('‚ö†Ô∏è No papers to index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Loading from ArXiv API\n",
    "\n",
    "Fetch papers directly from ArXiv using their API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Loading from ArXiv (requires arxiv package)\n",
    "try:\n",
    "    import arxiv\n",
    "    \n",
    "    print('üåê Fetching papers from ArXiv...')\n",
    "    \n",
    "    # Search for recent LLM papers\n",
    "    search = arxiv.Search(\n",
    "        query=\"ti:language model OR abs:transformer\",\n",
    "        max_results=5,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    \n",
    "    arxiv_papers = []\n",
    "    for result in search.results():\n",
    "        arxiv_papers.append({\n",
    "            'title': result.title,\n",
    "            'abstract': result.summary,\n",
    "            'authors': [author.name for author in result.authors],\n",
    "            'updated': result.updated.strftime('%Y-%m-%d'),\n",
    "            'arxiv_id': result.entry_id.split('/')[-1]\n",
    "        })\n",
    "    \n",
    "    print(f'‚úÖ Fetched {len(arxiv_papers)} papers from ArXiv')\n",
    "    \n",
    "    # Display results\n",
    "    for paper in arxiv_papers:\n",
    "        print(f'\\nüìÑ {paper[\"title\"]}')\n",
    "        print(f'   Authors: {\", \".join(paper[\"authors\"][:3])}...')\n",
    "        print(f'   ArXiv ID: {paper[\"arxiv_id\"]}')\n",
    "        \n",
    "except ImportError:\n",
    "    print('‚ö†Ô∏è arxiv package not installed.')\n",
    "    print('   Install with: pip install arxiv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Loading from JSON/CSV Files\n",
    "\n",
    "Load custom paper collections from structured files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample JSON file\n",
    "sample_papers = [\n",
    "    {\n",
    "        \"title\": \"Chain-of-Thought Prompting Elicits Reasoning\",\n",
    "        \"abstract\": \"We explore how generating a chain of thought...\",\n",
    "        \"authors\": [\"Wei et al.\"],\n",
    "        \"year\": 2022,\n",
    "        \"venue\": \"NeurIPS\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Constitutional AI: Harmlessness from AI Feedback\",\n",
    "        \"abstract\": \"We present Constitutional AI, a method for training...\",\n",
    "        \"authors\": [\"Bai et al.\"],\n",
    "        \"year\": 2022,\n",
    "        \"venue\": \"arXiv\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save to JSON\n",
    "json_path = Path('../data/sample_papers.json')\n",
    "json_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(sample_papers, f, indent=2)\n",
    "\n",
    "print(f'üíæ Saved sample papers to {json_path}')\n",
    "\n",
    "# Load from JSON\n",
    "with open(json_path) as f:\n",
    "    loaded_papers = json.load(f)\n",
    "\n",
    "print(f'\\n‚úÖ Loaded {len(loaded_papers)} papers from JSON')\n",
    "\n",
    "# Convert to DataFrame\n",
    "custom_df = pd.DataFrame(loaded_papers)\n",
    "display(custom_df)\n",
    "\n",
    "# Also demonstrate CSV loading\n",
    "csv_path = Path('../data/sample_papers.csv')\n",
    "custom_df.to_csv(csv_path, index=False)\n",
    "print(f'\\nüíæ Saved to CSV: {csv_path}')\n",
    "\n",
    "# Load from CSV\n",
    "csv_df = pd.read_csv(csv_path)\n",
    "print(f'‚úÖ Loaded {len(csv_df)} papers from CSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Combining Multiple Sources\n",
    "\n",
    "Merge papers from different sources for comprehensive coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine papers from multiple sources\n",
    "all_papers = []\n",
    "\n",
    "# Add papers from parquet\n",
    "if 'papers_df' in locals() and len(papers_df) > 0:\n",
    "    all_papers.extend(papers_df.head(10).to_dict('records'))\n",
    "    print(f'‚úÖ Added {min(10, len(papers_df))} papers from parquet')\n",
    "\n",
    "# Add papers from JSON\n",
    "if 'loaded_papers' in locals():\n",
    "    all_papers.extend(loaded_papers)\n",
    "    print(f'‚úÖ Added {len(loaded_papers)} papers from JSON')\n",
    "\n",
    "# Add papers from ArXiv\n",
    "if 'arxiv_papers' in locals():\n",
    "    all_papers.extend(arxiv_papers)\n",
    "    print(f'‚úÖ Added {len(arxiv_papers)} papers from ArXiv')\n",
    "\n",
    "print(f'\\nüìä Total papers collected: {len(all_papers)}')\n",
    "\n",
    "# Remove duplicates based on title\n",
    "unique_papers = []\n",
    "seen_titles = set()\n",
    "\n",
    "for paper in all_papers:\n",
    "    title = paper.get('title', '').lower()\n",
    "    if title and title not in seen_titles:\n",
    "        unique_papers.append(paper)\n",
    "        seen_titles.add(title)\n",
    "\n",
    "print(f'‚úÖ Unique papers after deduplication: {len(unique_papers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Data Preprocessing for Survey Generation\n",
    "\n",
    "Prepare papers for input to the survey generation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_papers(papers, max_papers=50):\n",
    "    \"\"\"Preprocess papers for survey generation.\"\"\"\n",
    "    \n",
    "    # Ensure required fields\n",
    "    processed = []\n",
    "    for paper in papers[:max_papers]:\n",
    "        # Clean and standardize fields\n",
    "        processed_paper = {\n",
    "            'title': paper.get('title', 'Untitled'),\n",
    "            'abstract': paper.get('abstract', paper.get('summary', '')),\n",
    "            'authors': paper.get('authors', []),\n",
    "            'year': None,\n",
    "            'venue': paper.get('venue', '')\n",
    "        }\n",
    "        \n",
    "        # Extract year\n",
    "        if 'year' in paper:\n",
    "            processed_paper['year'] = paper['year']\n",
    "        elif 'updated' in paper:\n",
    "            try:\n",
    "                date = pd.to_datetime(paper['updated'])\n",
    "                processed_paper['year'] = date.year\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Ensure authors is a list\n",
    "        if isinstance(processed_paper['authors'], str):\n",
    "            processed_paper['authors'] = [processed_paper['authors']]\n",
    "        \n",
    "        # Truncate abstract if too long\n",
    "        if len(processed_paper['abstract']) > 1000:\n",
    "            processed_paper['abstract'] = processed_paper['abstract'][:997] + '...'\n",
    "        \n",
    "        processed.append(processed_paper)\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# Preprocess papers\n",
    "if unique_papers:\n",
    "    survey_papers = preprocess_papers(unique_papers, max_papers=20)\n",
    "    \n",
    "    print(f'‚úÖ Preprocessed {len(survey_papers)} papers for survey generation')\n",
    "    print('\\nüìÑ Sample preprocessed paper:')\n",
    "    \n",
    "    sample = survey_papers[0]\n",
    "    print(f\"  Title: {sample['title']}\")\n",
    "    print(f\"  Authors: {', '.join(sample['authors'][:3]) if sample['authors'] else 'Unknown'}\")\n",
    "    print(f\"  Year: {sample['year'] or 'Unknown'}\")\n",
    "    print(f\"  Abstract: {sample['abstract'][:100]}...\" if sample['abstract'] else \"  Abstract: None\")\n",
    "    \n",
    "    # Save for survey generation\n",
    "    output_path = Path('../data/preprocessed_papers.json')\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(survey_papers, f, indent=2)\n",
    "    \n",
    "    print(f'\\nüíæ Saved preprocessed papers to {output_path}')\n",
    "else:\n",
    "    print('‚ö†Ô∏è No papers to preprocess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Data Quality Checks\n",
    "\n",
    "Validate data quality before survey generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_quality(papers):\n",
    "    \"\"\"Check data quality and completeness.\"\"\"\n",
    "    \n",
    "    print('üîç Data Quality Report')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Overall stats\n",
    "    print(f'Total papers: {len(papers)}')\n",
    "    \n",
    "    # Check field completeness\n",
    "    fields = ['title', 'abstract', 'authors', 'year']\n",
    "    completeness = {}\n",
    "    \n",
    "    for field in fields:\n",
    "        count = sum(1 for p in papers if p.get(field))\n",
    "        completeness[field] = count / len(papers) * 100\n",
    "    \n",
    "    print('\\nüìä Field Completeness:')\n",
    "    for field, pct in completeness.items():\n",
    "        bar = '‚ñà' * int(pct / 5)\n",
    "        print(f'  {field:10s}: {bar:20s} {pct:.1f}%')\n",
    "    \n",
    "    # Check abstract lengths\n",
    "    abstract_lengths = [len(p.get('abstract', '')) for p in papers]\n",
    "    avg_length = np.mean(abstract_lengths) if abstract_lengths else 0\n",
    "    \n",
    "    print(f'\\nüìù Abstract Statistics:')\n",
    "    print(f'  Average length: {avg_length:.0f} characters')\n",
    "    print(f'  Min length: {min(abstract_lengths) if abstract_lengths else 0}')\n",
    "    print(f'  Max length: {max(abstract_lengths) if abstract_lengths else 0}')\n",
    "    \n",
    "    # Year distribution\n",
    "    years = [p.get('year') for p in papers if p.get('year')]\n",
    "    if years:\n",
    "        print(f'\\nüìÖ Year Distribution:')\n",
    "        print(f'  Earliest: {min(years)}')\n",
    "        print(f'  Latest: {max(years)}')\n",
    "        print(f'  Median: {np.median(years):.0f}')\n",
    "    \n",
    "    # Quality score\n",
    "    quality_score = np.mean(list(completeness.values()))\n",
    "    \n",
    "    print(f'\\n‚≠ê Overall Quality Score: {quality_score:.1f}/100')\n",
    "    \n",
    "    if quality_score < 70:\n",
    "        print('‚ö†Ô∏è Warning: Data quality is below recommended threshold (70%)')\n",
    "        print('   Consider adding more complete paper metadata.')\n",
    "    else:\n",
    "        print('‚úÖ Data quality is sufficient for survey generation')\n",
    "    \n",
    "    return quality_score\n",
    "\n",
    "# Run quality check\n",
    "if 'survey_papers' in locals() and survey_papers:\n",
    "    quality_score = check_data_quality(survey_papers)\n",
    "else:\n",
    "    print('‚ö†Ô∏è No papers available for quality check')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary & Next Steps\n",
    "\n",
    "### What We Covered\n",
    "1. ‚úÖ Loading papers from parquet files\n",
    "2. ‚úÖ Topic-based filtering\n",
    "3. ‚úÖ BM25 search engine usage\n",
    "4. ‚úÖ ArXiv API integration\n",
    "5. ‚úÖ JSON/CSV file handling\n",
    "6. ‚úÖ Combining multiple sources\n",
    "7. ‚úÖ Data preprocessing\n",
    "8. ‚úÖ Quality validation\n",
    "\n",
    "### Key Takeaways\n",
    "- **Flexibility**: Load papers from various sources\n",
    "- **Scalability**: Handle datasets with 100,000+ papers\n",
    "- **Quality**: Validate data before survey generation\n",
    "- **Search**: Use BM25 for efficient relevance-based retrieval\n",
    "\n",
    "### Next Steps\n",
    "1. **Generate Survey**: Use loaded papers with survey generation systems\n",
    "2. **Explore Trends**: Analyze temporal patterns in your dataset\n",
    "3. **Custom Sources**: Add your own paper sources\n",
    "4. **API Integration**: Use the FastAPI endpoints for programmatic access\n",
    "\n",
    "### üìö Related Notebooks\n",
    "- **[02_survey_generation_comparison.ipynb](02_survey_generation_comparison.ipynb)** - Compare generation methods\n",
    "- **[03_results_visualization.ipynb](03_results_visualization.ipynb)** - Visualize survey quality\n",
    "- **[04_api_integration_example.ipynb](04_api_integration_example.ipynb)** - Use the REST API\n",
    "- **[05_quick_start_tutorial.ipynb](05_quick_start_tutorial.ipynb)** - Quick start guide\n",
    "\n",
    "### üí° Tips\n",
    "- For large datasets, use parquet files for best performance\n",
    "- Combine multiple sources for comprehensive coverage\n",
    "- Always validate data quality before generation\n",
    "- Use BM25 search for topic-specific paper selection\n",
    "\n",
    "Happy researching! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}