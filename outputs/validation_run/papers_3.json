[
  {
    "entry_id": "http://arxiv.org/abs/2505.06416v1",
    "updated": "2025-05-09T20:30:37+00:00",
    "published": "2025-05-09T20:30:37+00:00",
    "title": "ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents",
    "authors": "['Elias Lumer' 'Anmol Gulati' 'Vamse Kumar Subbiah'\n 'Pradeep Honaganahalli Basavaraju' 'James A. Burke']",
    "summary": "Recent advancements in Large Language Models (LLMs) and the introduction of\nthe Model Context Protocol (MCP) have significantly expanded LLM agents'\ncapability to interact dynamically with external tools and APIs. However,\nexisting tool selection frameworks do not integrate MCP servers, instead\nrelying heavily on error-prone manual updates to monolithic local tool\nrepositories, leading to duplication, inconsistencies, and inefficiencies.\nAdditionally, current approaches abstract tool selection before the LLM agent\nis invoked, limiting its autonomy and hindering dynamic re-querying\ncapabilities during multi-turn interactions. To address these issues, we\nintroduce ScaleMCP, a novel tool selection approach that dynamically equips LLM\nagents with a MCP tool retriever, giving agents the autonomy to add tools into\ntheir memory, as well as an auto-synchronizing tool storage system pipeline\nthrough CRUD (create, read, update, delete) operations with MCP servers as the\nsingle source of truth. We also propose a novel embedding strategy, Tool\nDocument Weighted Average (TDWA), designed to selectively emphasize critical\ncomponents of tool documents (e.g. tool name or synthetic questions) during the\nembedding process. Comprehensive evaluations conducted on a created dataset of\n5,000 financial metric MCP servers, across 10 LLM models, 5 embedding models,\nand 5 retriever types, demonstrate substantial improvements in tool retrieval\nand agent invocation performance, emphasizing ScaleMCP's effectiveness in\nscalable, dynamic tool selection and invocation.",
    "comment": "17 pages",
    "journal_ref": null,
    "doi": null,
    "primary_category": "cs.CL",
    "categories": "['cs.CL']",
    "links": "['http://arxiv.org/abs/2505.06416v1' 'http://arxiv.org/pdf/2505.06416v1']",
    "pdf_url": "http://arxiv.org/pdf/2505.06416v1",
    "arxiv_id": "2505.06416",
    "row_id": 463478,
    "year": 2025,
    "processed_text": "ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents Recent advancements in Large Language Models (LLMs) and the introduction of\nthe Model Context Protocol (MCP) have significantly expanded LLM agents'\ncapability to interact dynamically with external tools and APIs. However,\nexisting tool selection frameworks do not integrate MCP servers, instead\nrelying heavily on error-prone manual updates to monolithic local tool\nrepositories, leading to duplication, inconsistencies, and inefficiencies.\nAdditionally, current approaches abstract tool selection before the LLM agent\nis invoked, limiting its autonomy and hindering dynamic re-querying\ncapabilities during multi-turn interactions. To address these issues, we\nintroduce ScaleMCP, a novel tool selection approach that dynamically equips LLM\nagents with a MCP tool retriever, giving agents the autonomy to add tools into\ntheir memory, as well as an auto-synchronizing tool storage system pipeline\nthrough CRUD (create, read, update, delete) operations with MCP servers as the\nsingle source of truth. We also propose a novel embedding strategy, Tool\nDocument Weighted Average (TDWA), designed to selectively emphasize critical\ncomponents of tool documents (e.g. tool name or synthetic questions) during the\nembedding process. Comprehensive evaluations conducted on a created dataset of\n5,000 financial metric MCP servers, across 10 LLM models, 5 embedding models,\nand 5 retriever types, demonstrate substantial improvements in tool retrieval\nand agent invocation performance, emphasizing ScaleMCP's effectiveness in\nscalable, dynamic tool selection and invocation.",
    "bm25_score": 16.056429555698458
  },
  {
    "entry_id": "http://arxiv.org/abs/2505.22368v1",
    "updated": "2025-05-28T13:56:22+00:00",
    "published": "2025-05-28T13:56:22+00:00",
    "title": "AgentDNS: A Root Domain Naming System for LLM Agents",
    "authors": "['Enfang Cui' 'Yujun Cheng' 'Rui She' 'Dan Liu' 'Zhiyuan Liang'\n 'Minxin Guo' 'Tianzheng Li' 'Qian Wei' 'Wenjuan Xing' 'Zhijie Zhong']",
    "summary": "The rapid evolution of Large Language Model (LLM) agents has highlighted\ncritical challenges in cross-vendor service discovery, interoperability, and\ncommunication. Existing protocols like model context protocol and\nagent-to-agent protocol have made significant strides in standardizing\ninteroperability between agents and tools, as well as communication among\nmulti-agents. However, there remains a lack of standardized protocols and\nsolutions for service discovery across different agent and tool vendors. In\nthis paper, we propose AgentDNS, a root domain naming and service discovery\nsystem designed to enable LLM agents to autonomously discover, resolve, and\nsecurely invoke third-party agent and tool services across organizational and\ntechnological boundaries. Inspired by the principles of the traditional DNS,\nAgentDNS introduces a structured mechanism for service registration, semantic\nservice discovery, secure invocation, and unified billing. We detail the\narchitecture, core functionalities, and use cases of AgentDNS, demonstrating\nits potential to streamline multi-agent collaboration in real-world scenarios.\nThe source code will be published on https://github.com/agentdns.",
    "comment": "7 pages, 6 figures",
    "journal_ref": null,
    "doi": null,
    "primary_category": "cs.AI",
    "categories": "['cs.AI']",
    "links": "['http://arxiv.org/abs/2505.22368v1' 'http://arxiv.org/pdf/2505.22368v1']",
    "pdf_url": "http://arxiv.org/pdf/2505.22368v1",
    "arxiv_id": "2505.22368",
    "row_id": 460070,
    "year": 2025,
    "processed_text": "AgentDNS: A Root Domain Naming System for LLM Agents The rapid evolution of Large Language Model (LLM) agents has highlighted\ncritical challenges in cross-vendor service discovery, interoperability, and\ncommunication. Existing protocols like model context protocol and\nagent-to-agent protocol have made significant strides in standardizing\ninteroperability between agents and tools, as well as communication among\nmulti-agents. However, there remains a lack of standardized protocols and\nsolutions for service discovery across different agent and tool vendors. In\nthis paper, we propose AgentDNS, a root domain naming and service discovery\nsystem designed to enable LLM agents to autonomously discover, resolve, and\nsecurely invoke third-party agent and tool services across organizational and\ntechnological boundaries. Inspired by the principles of the traditional DNS,\nAgentDNS introduces a structured mechanism for service registration, semantic\nservice discovery, secure invocation, and unified billing. We detail the\narchitecture, core functionalities, and use cases of AgentDNS, demonstrating\nits potential to streamline multi-agent collaboration in real-world scenarios.\nThe source code will be published on https://github.com/agentdns.",
    "bm25_score": 15.709259900325698
  },
  {
    "entry_id": "http://arxiv.org/abs/2502.09809v1",
    "updated": "2025-02-13T23:00:33+00:00",
    "published": "2025-02-13T23:00:33+00:00",
    "title": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration",
    "authors": "['Jizhou Chen' 'Samuel Lee Cong']",
    "summary": "The integration of tool use into large language models (LLMs) enables agentic\nsystems with real-world impact. In the meantime, unlike standalone LLMs,\ncompromised agents can execute malicious workflows with more consequential\nimpact, signified by their tool-use capability. We propose AgentGuard, a\nframework to autonomously discover and validate unsafe tool-use workflows,\nfollowed by generating safety constraints to confine the behaviors of agents,\nachieving the baseline of safety guarantee at deployment. AgentGuard leverages\nthe LLM orchestrator's innate capabilities - knowledge of tool functionalities,\nscalable and realistic workflow generation, and tool execution privileges - to\nact as its own safety evaluator. The framework operates through four phases:\nidentifying unsafe workflows, validating them in real-world execution,\ngenerating safety constraints, and validating constraint efficacy. The output,\nan evaluation report with unsafe workflows, test cases, and validated\nconstraints, enables multiple security applications. We empirically demonstrate\nAgentGuard's feasibility with experiments. With this exploratory work, we hope\nto inspire the establishment of standardized testing and hardening procedures\nfor LLM agents to enhance their trustworthiness in real-world applications.",
    "comment": "Project report of AgentGuard in LLM Agent MOOC Hackathon hosted by UC\n  Berkeley in 2024",
    "journal_ref": null,
    "doi": null,
    "primary_category": "cs.CR",
    "categories": "['cs.CR' 'cs.AI']",
    "links": "['http://arxiv.org/abs/2502.09809v1' 'http://arxiv.org/pdf/2502.09809v1']",
    "pdf_url": "http://arxiv.org/pdf/2502.09809v1",
    "arxiv_id": "2502.09809",
    "row_id": 83666,
    "year": 2025,
    "processed_text": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration The integration of tool use into large language models (LLMs) enables agentic\nsystems with real-world impact. In the meantime, unlike standalone LLMs,\ncompromised agents can execute malicious workflows with more consequential\nimpact, signified by their tool-use capability. We propose AgentGuard, a\nframework to autonomously discover and validate unsafe tool-use workflows,\nfollowed by generating safety constraints to confine the behaviors of agents,\nachieving the baseline of safety guarantee at deployment. AgentGuard leverages\nthe LLM orchestrator's innate capabilities - knowledge of tool functionalities,\nscalable and realistic workflow generation, and tool execution privileges - to\nact as its own safety evaluator. The framework operates through four phases:\nidentifying unsafe workflows, validating them in real-world execution,\ngenerating safety constraints, and validating constraint efficacy. The output,\nan evaluation report with unsafe workflows, test cases, and validated\nconstraints, enables multiple security applications. We empirically demonstrate\nAgentGuard's feasibility with experiments. With this exploratory work, we hope\nto inspire the establishment of standardized testing and hardening procedures\nfor LLM agents to enhance their trustworthiness in real-world applications.",
    "bm25_score": 15.399665830317959
  }
]