{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåê API Integration Example - LLM Survey Generator\n",
    "\n",
    "This notebook demonstrates how to interact with the LLM Survey Generator REST API and WebSocket endpoints.\n",
    "\n",
    "## Features Covered\n",
    "1. **Authentication** - API key setup\n",
    "2. **Paper Upload** - Submit papers for processing\n",
    "3. **Survey Generation** - Create surveys via API\n",
    "4. **Real-time Monitoring** - WebSocket progress tracking\n",
    "5. **Result Retrieval** - Get completed surveys\n",
    "6. **Batch Processing** - Multiple surveys in parallel\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "import websockets\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# API Configuration\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "API_KEY = \"your-api-key-here\"  # Replace with actual key\n",
    "\n",
    "# Set up headers\n",
    "headers = {\n",
    "    \"api-key\": API_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(\"üîß API Client Configuration\")\n",
    "print(f\"  Base URL: {BASE_URL}\")\n",
    "print(f\"  API Key: {'*' * 10}...\")\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    response = requests.get(f\"{BASE_URL}/health\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ API is online and healthy\")\n",
    "        print(f\"  Status: {response.json()}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è API may be offline. Start with: uvicorn src.api.main:app\")\n",
    "except:\n",
    "    print(\"‚ùå Cannot connect to API. Please start the server first.\")\n",
    "    print(\"   Run: uvicorn src.api.main:app --reload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Upload Papers to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample paper data\n",
    "sample_papers = [\n",
    "    {\n",
    "        \"title\": \"Attention Is All You Need\",\n",
    "        \"abstract\": \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms.\",\n",
    "        \"authors\": [\"Vaswani et al.\"],\n",
    "        \"year\": 2017\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers\",\n",
    "        \"abstract\": \"We introduce BERT, which stands for Bidirectional Encoder Representations from Transformers. BERT is designed to pre-train deep bidirectional representations.\",\n",
    "        \"authors\": [\"Devlin et al.\"],\n",
    "        \"year\": 2018\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Language Models are Few-Shot Learners\",\n",
    "        \"abstract\": \"We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance.\",\n",
    "        \"authors\": [\"Brown et al.\"],\n",
    "        \"year\": 2020\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save papers to JSON file\n",
    "papers_file = Path('../data/api_papers.json')\n",
    "papers_file.parent.mkdir(exist_ok=True)\n",
    "with open(papers_file, 'w') as f:\n",
    "    json.dump(sample_papers, f, indent=2)\n",
    "\n",
    "print(f\"üìÑ Created {len(sample_papers)} sample papers\")\n",
    "\n",
    "# Upload papers via API\n",
    "paper_ids = []\n",
    "\n",
    "# Note: In production, you'd upload PDF files\n",
    "# This is a simplified example using JSON data\n",
    "for paper in sample_papers:\n",
    "    # Simulate upload (in real API, use multipart/form-data with PDF)\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/papers\",\n",
    "        json=paper,\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        paper_id = response.json().get('paper_id', f\"demo-{len(paper_ids)}\")\n",
    "        paper_ids.append(paper_id)\n",
    "        print(f\"‚úÖ Uploaded: {paper['title'][:50]}...\")\n",
    "        print(f\"   Paper ID: {paper_id}\")\n",
    "    else:\n",
    "        # For demo, create mock IDs\n",
    "        paper_id = f\"demo-{len(paper_ids)}\"\n",
    "        paper_ids.append(paper_id)\n",
    "        print(f\"üìù Demo mode - Paper ID: {paper_id}\")\n",
    "\n",
    "print(f\"\\nüéØ Total papers uploaded: {len(paper_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Create Survey Generation Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create survey request\n",
    "survey_request = {\n",
    "    \"topic\": \"Evolution of Transformer-based Language Models\",\n",
    "    \"paper_ids\": paper_ids,\n",
    "    \"system_type\": \"iterative\",  # Options: baseline, lce, iterative\n",
    "    \"max_iterations\": 3,\n",
    "    \"model_preference\": \"balanced\"  # Options: fast, balanced, complex\n",
    "}\n",
    "\n",
    "print(\"üìù Survey Request:\")\n",
    "print(json.dumps(survey_request, indent=2))\n",
    "\n",
    "# Submit survey generation request\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/surveys\",\n",
    "        json=survey_request,\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        survey_data = response.json()\n",
    "        survey_id = survey_data['survey_id']\n",
    "        print(f\"\\n‚úÖ Survey job created!\")\n",
    "        print(f\"   Survey ID: {survey_id}\")\n",
    "        print(f\"   Status: {survey_data['status']}\")\n",
    "    else:\n",
    "        # Demo mode\n",
    "        survey_id = \"demo-survey-001\"\n",
    "        print(f\"\\nüìù Demo mode - Survey ID: {survey_id}\")\n",
    "except:\n",
    "    survey_id = \"demo-survey-001\"\n",
    "    print(f\"\\nüìù Demo mode (API offline) - Survey ID: {survey_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Monitor Progress with Polling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_survey_status(survey_id, max_polls=10, interval=2):\n",
    "    \"\"\"Poll survey status until completion.\"\"\"\n",
    "    \n",
    "    print(f\"üîÑ Monitoring survey: {survey_id}\\n\")\n",
    "    \n",
    "    for i in range(max_polls):\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/surveys/{survey_id}/status\",\n",
    "                headers=headers\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                status_data = response.json()\n",
    "            else:\n",
    "                # Demo fallback\n",
    "                status_data = {\n",
    "                    \"status\": \"processing\" if i < 5 else \"completed\",\n",
    "                    \"current_iteration\": min(i // 2 + 1, 3),\n",
    "                    \"current_phase\": [\"generating\", \"verifying\", \"improving\"][i % 3],\n",
    "                    \"quality_score\": 3.5 + (i * 0.1)\n",
    "                }\n",
    "        except:\n",
    "            # Demo mode when API is offline\n",
    "            status_data = {\n",
    "                \"status\": \"processing\" if i < 5 else \"completed\",\n",
    "                \"current_iteration\": min(i // 2 + 1, 3),\n",
    "                \"current_phase\": [\"generating\", \"verifying\", \"improving\"][i % 3],\n",
    "                \"quality_score\": 3.5 + (i * 0.1)\n",
    "            }\n",
    "        \n",
    "        # Display status\n",
    "        clear_output(wait=True)\n",
    "        print(f\"üîÑ Survey Status Update [{i+1}/{max_polls}]\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Status: {status_data['status'].upper()}\")\n",
    "        print(f\"Iteration: {status_data.get('current_iteration', 'N/A')}\")\n",
    "        print(f\"Phase: {status_data.get('current_phase', 'N/A')}\")\n",
    "        print(f\"Quality Score: {status_data.get('quality_score', 0):.2f}\")\n",
    "        \n",
    "        # Progress bar\n",
    "        progress = (i + 1) / max_polls\n",
    "        bar_length = 30\n",
    "        filled = int(bar_length * progress)\n",
    "        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)\n",
    "        print(f\"\\nProgress: [{bar}] {progress*100:.0f}%\")\n",
    "        \n",
    "        if status_data['status'] == 'completed':\n",
    "            print(\"\\n‚úÖ Survey generation completed!\")\n",
    "            return status_data\n",
    "        \n",
    "        time.sleep(interval)\n",
    "    \n",
    "    print(\"\\n‚è±Ô∏è Polling timeout. Survey may still be processing.\")\n",
    "    return status_data\n",
    "\n",
    "# Poll for status\n",
    "final_status = poll_survey_status(survey_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Real-time Monitoring with WebSocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebSocket monitoring (requires async)\n",
    "async def monitor_with_websocket(survey_id):\n",
    "    \"\"\"Connect to WebSocket for real-time updates.\"\"\"\n",
    "    \n",
    "    ws_url = f\"ws://localhost:8000/ws/{survey_id}\"\n",
    "    print(f\"üåê Connecting to WebSocket: {ws_url}\\n\")\n",
    "    \n",
    "    try:\n",
    "        async with websockets.connect(ws_url) as websocket:\n",
    "            while True:\n",
    "                message = await websocket.recv()\n",
    "                data = json.loads(message)\n",
    "                \n",
    "                # Display update\n",
    "                clear_output(wait=True)\n",
    "                print(\"üî¥ LIVE WebSocket Update\")\n",
    "                print(\"=\" * 50)\n",
    "                print(f\"Survey ID: {data.get('survey_id', survey_id)}\")\n",
    "                print(f\"Status: {data.get('status', 'unknown').upper()}\")\n",
    "                print(f\"Iteration: {data.get('current_iteration', 'N/A')}/3\")\n",
    "                print(f\"Phase: {data.get('current_phase', 'N/A')}\")\n",
    "                print(f\"Quality: {data.get('quality_score', 0):.2f}/5.00\")\n",
    "                \n",
    "                if data.get('status') == 'completed':\n",
    "                    print(\"\\n‚úÖ Survey completed via WebSocket!\")\n",
    "                    break\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è WebSocket not available: {e}\")\n",
    "        print(\"Falling back to polling...\")\n",
    "\n",
    "# Note: In Jupyter, use this to run async code\n",
    "try:\n",
    "    # Try to connect to WebSocket\n",
    "    await monitor_with_websocket(survey_id)\n",
    "except:\n",
    "    print(\"üìù WebSocket demo - would show real-time updates in production\")\n",
    "    print(\"   Status: Processing ‚Üí Verifying ‚Üí Improving ‚Üí Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Retrieve Completed Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get completed survey\n",
    "def get_survey(survey_id, format='json'):\n",
    "    \"\"\"Retrieve completed survey.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{BASE_URL}/surveys/{survey_id}\",\n",
    "            params={'format': format},\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json() if format == 'json' else response.text\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Demo fallback\n",
    "    return {\n",
    "        \"title\": \"Survey on Evolution of Transformer-based Language Models\",\n",
    "        \"sections\": [\n",
    "            {\n",
    "                \"title\": \"Introduction\",\n",
    "                \"content\": \"Transformer models have revolutionized NLP since 2017...\",\n",
    "                \"citations\": [\"Vaswani et al.\", \"Devlin et al.\"]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Architecture Evolution\",\n",
    "                \"content\": \"From attention mechanisms to BERT and GPT...\",\n",
    "                \"citations\": [\"Brown et al.\"]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Applications\",\n",
    "                \"content\": \"Modern applications span from translation to generation...\",\n",
    "                \"citations\": [\"Devlin et al.\", \"Brown et al.\"]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"Conclusion\",\n",
    "                \"content\": \"Transformers continue to advance the field...\",\n",
    "                \"citations\": []\n",
    "            }\n",
    "        ],\n",
    "        \"quality_score\": 4.11,\n",
    "        \"iterations\": 3,\n",
    "        \"generation_time\": 45.2\n",
    "    }\n",
    "\n",
    "# Get survey in JSON format\n",
    "survey_json = get_survey(survey_id, format='json')\n",
    "\n",
    "print(\"üìÑ Retrieved Survey:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Title: {survey_json['title']}\")\n",
    "print(f\"Sections: {len(survey_json['sections'])}\")\n",
    "print(f\"Quality Score: {survey_json['quality_score']:.2f}/5.00\")\n",
    "print(f\"Iterations: {survey_json['iterations']}\")\n",
    "print(f\"Generation Time: {survey_json.get('generation_time', 'N/A')}s\")\n",
    "\n",
    "# Display sections\n",
    "print(\"\\nüìö Survey Sections:\")\n",
    "for i, section in enumerate(survey_json['sections'], 1):\n",
    "    print(f\"  {i}. {section['title']}\")\n",
    "    print(f\"     Content: {section['content'][:80]}...\")\n",
    "    print(f\"     Citations: {len(section['citations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Batch Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple survey jobs\n",
    "batch_topics = [\n",
    "    \"Transformer Architectures\",\n",
    "    \"Pre-training Methods\",\n",
    "    \"Few-shot Learning\"\n",
    "]\n",
    "\n",
    "batch_jobs = []\n",
    "\n",
    "print(\"üöÄ Starting batch processing...\\n\")\n",
    "\n",
    "for topic in batch_topics:\n",
    "    request = {\n",
    "        \"topic\": topic,\n",
    "        \"paper_ids\": paper_ids[:2],  # Use subset for speed\n",
    "        \"system_type\": \"iterative\",\n",
    "        \"max_iterations\": 2  # Fewer iterations for batch\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{BASE_URL}/surveys\",\n",
    "            json=request,\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            job_id = response.json()['survey_id']\n",
    "        else:\n",
    "            job_id = f\"batch-{len(batch_jobs)}\"\n",
    "    except:\n",
    "        job_id = f\"batch-demo-{len(batch_jobs)}\"\n",
    "    \n",
    "    batch_jobs.append({\n",
    "        'id': job_id,\n",
    "        'topic': topic,\n",
    "        'status': 'submitted',\n",
    "        'start_time': datetime.now()\n",
    "    })\n",
    "    \n",
    "    print(f\"üìù Submitted: {topic}\")\n",
    "    print(f\"   Job ID: {job_id}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Batch submitted: {len(batch_jobs)} jobs\")\n",
    "\n",
    "# Monitor batch\n",
    "print(\"\\n‚è≥ Monitoring batch progress...\\n\")\n",
    "\n",
    "for _ in range(5):  # Simulate monitoring\n",
    "    clear_output(wait=True)\n",
    "    print(\"üìä Batch Status Dashboard\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for job in batch_jobs:\n",
    "        # Simulate status updates\n",
    "        if job['status'] == 'submitted':\n",
    "            job['status'] = 'processing'\n",
    "        elif job['status'] == 'processing':\n",
    "            job['status'] = 'completed' if _ > 2 else 'processing'\n",
    "        \n",
    "        status_icon = {'submitted': 'üìù', 'processing': 'üîÑ', 'completed': '‚úÖ'}[job['status']]\n",
    "        print(f\"{status_icon} {job['topic'][:30]:30s} | {job['status']:10s} | {job['id']}\")\n",
    "    \n",
    "    completed = sum(1 for j in batch_jobs if j['status'] == 'completed')\n",
    "    print(f\"\\nüìà Progress: {completed}/{len(batch_jobs)} completed\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\nüéâ Batch processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Advanced API Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all papers\n",
    "def list_papers(skip=0, limit=10):\n",
    "    \"\"\"List uploaded papers with pagination.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{BASE_URL}/papers\",\n",
    "            params={'skip': skip, 'limit': limit},\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Demo fallback\n",
    "    return {\n",
    "        'total': len(sample_papers),\n",
    "        'papers': sample_papers[skip:skip+limit]\n",
    "    }\n",
    "\n",
    "# Get paper list\n",
    "papers_list = list_papers()\n",
    "print(\"üìö Available Papers:\")\n",
    "print(f\"Total: {papers_list.get('total', len(sample_papers))}\\n\")\n",
    "\n",
    "for i, paper in enumerate(papers_list.get('papers', sample_papers), 1):\n",
    "    print(f\"{i}. {paper['title']} ({paper.get('year', 'N/A')})\")\n",
    "\n",
    "# Check rate limits\n",
    "print(\"\\n‚ö†Ô∏è Rate Limits:\")\n",
    "print(\"  ‚Ä¢ /upload: 30 requests/minute\")\n",
    "print(\"  ‚Ä¢ /surveys: 10 requests/minute\")\n",
    "print(\"  ‚Ä¢ Other endpoints: No limit\")\n",
    "\n",
    "# Error handling example\n",
    "print(\"\\nüõ°Ô∏è Error Handling Example:\")\n",
    "\n",
    "# Try invalid request\n",
    "invalid_request = {\n",
    "    \"topic\": \"\",  # Empty topic\n",
    "    \"system_type\": \"invalid\"  # Invalid system\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/surveys\",\n",
    "        json=invalid_request,\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error {response.status_code}: {response.json().get('detail', 'Invalid request')}\")\n",
    "except:\n",
    "    print(\"Error 400: Invalid request parameters (demo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export survey to different formats\n",
    "def export_survey(survey, format='markdown'):\n",
    "    \"\"\"Export survey in different formats.\"\"\"\n",
    "    \n",
    "    if format == 'markdown':\n",
    "        md = f\"# {survey['title']}\\n\\n\"\n",
    "        \n",
    "        for section in survey['sections']:\n",
    "            md += f\"## {section['title']}\\n\\n\"\n",
    "            md += f\"{section['content']}\\n\\n\"\n",
    "            \n",
    "            if section['citations']:\n",
    "                md += \"**References:**\\n\"\n",
    "                for cite in section['citations']:\n",
    "                    md += f\"- {cite}\\n\"\n",
    "                md += \"\\n\"\n",
    "        \n",
    "        return md\n",
    "    \n",
    "    elif format == 'html':\n",
    "        html = f\"<h1>{survey['title']}</h1>\\n\"\n",
    "        \n",
    "        for section in survey['sections']:\n",
    "            html += f\"<h2>{section['title']}</h2>\\n\"\n",
    "            html += f\"<p>{section['content']}</p>\\n\"\n",
    "            \n",
    "            if section['citations']:\n",
    "                html += \"<p><em>Citations: \"\n",
    "                html += \", \".join(section['citations'])\n",
    "                html += \"</em></p>\\n\"\n",
    "        \n",
    "        return html\n",
    "    \n",
    "    return survey  # Default JSON\n",
    "\n",
    "# Export in different formats\n",
    "output_dir = Path('../outputs/api_exports')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save as Markdown\n",
    "md_content = export_survey(survey_json, format='markdown')\n",
    "md_path = output_dir / f\"survey_{survey_id}.md\"\n",
    "with open(md_path, 'w') as f:\n",
    "    f.write(md_content)\n",
    "print(f\"üìù Exported Markdown: {md_path}\")\n",
    "\n",
    "# Save as HTML\n",
    "html_content = export_survey(survey_json, format='html')\n",
    "html_path = output_dir / f\"survey_{survey_id}.html\"\n",
    "with open(html_path, 'w') as f:\n",
    "    f.write(html_content)\n",
    "print(f\"üåê Exported HTML: {html_path}\")\n",
    "\n",
    "# Save as JSON\n",
    "json_path = output_dir / f\"survey_{survey_id}.json\"\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(survey_json, f, indent=2)\n",
    "print(f\"üìÑ Exported JSON: {json_path}\")\n",
    "\n",
    "# Display preview\n",
    "print(\"\\nüìñ Markdown Preview:\")\n",
    "print(\"=\" * 50)\n",
    "display(Markdown(md_content[:500] + \"...\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ API Integration Best Practices\n",
    "\n",
    "### Authentication\n",
    "```python\n",
    "# Store API key securely\n",
    "import os\n",
    "API_KEY = os.environ.get('SURVEY_API_KEY')\n",
    "```\n",
    "\n",
    "### Error Handling\n",
    "```python\n",
    "try:\n",
    "    response = requests.post(...)\n",
    "    response.raise_for_status()\n",
    "except requests.exceptions.RequestException as e:\n",
    "    handle_error(e)\n",
    "```\n",
    "\n",
    "### Rate Limiting\n",
    "```python\n",
    "from time import sleep\n",
    "from functools import wraps\n",
    "\n",
    "def rate_limit(max_calls=10, period=60):\n",
    "    # Implement rate limiting decorator\n",
    "    pass\n",
    "```\n",
    "\n",
    "### WebSocket Reconnection\n",
    "```python\n",
    "async def connect_with_retry(url, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return await websockets.connect(url)\n",
    "        except:\n",
    "            await asyncio.sleep(2 ** attempt)\n",
    "```\n",
    "\n",
    "### Batch Processing\n",
    "```python\n",
    "# Use asyncio for concurrent requests\n",
    "async def batch_process(topics):\n",
    "    tasks = [create_survey(topic) for topic in topics]\n",
    "    return await asyncio.gather(*tasks)\n",
    "```\n",
    "\n",
    "## üìö API Documentation Links\n",
    "\n",
    "- **Interactive Docs**: http://localhost:8000/docs\n",
    "- **ReDoc**: http://localhost:8000/redoc\n",
    "- **OpenAPI Schema**: http://localhost:8000/openapi.json\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Production Deployment**\n",
    "   - Use HTTPS with SSL certificates\n",
    "   - Implement API key rotation\n",
    "   - Set up monitoring and alerts\n",
    "\n",
    "2. **Advanced Features**\n",
    "   - Custom model selection per request\n",
    "   - Priority queue for urgent surveys\n",
    "   - Scheduled survey generation\n",
    "\n",
    "3. **Integration Options**\n",
    "   - Build a web frontend\n",
    "   - Create mobile app\n",
    "   - Integrate with research tools\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook demonstrates complete API integration for the LLM Survey Generator system.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}